{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASMT-College/lab-3-classification-prabin2058/blob/main/Lab_3_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to predict whether a patient has diabetes based on certain health attributes using two classification algorithms:\n",
        "\n",
        "**Naive Bayes** and\n",
        "\n",
        "**ID3 Decision Tree**.\n",
        "\n",
        "After building both models, we'll compare their performance using metrics like accuracy, precision, recall, and F1-score.\n",
        "\n",
        "**Dataset: diabetes_data.csv**\n",
        "\n",
        "You can use the Pima Indians Diabetes dataset, which contains the following attributes:\n",
        "\n",
        "**Pregnancies:** Number of times pregnant\n",
        "\n",
        "**Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure:** Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness:** Triceps skinfold thickness (mm)\n",
        "\n",
        "**Insulin:** 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI:** Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction:** Diabetes pedigree function\n",
        "\n",
        "**Age:** Age (years)\n",
        "\n",
        "**Outcome: Class variable (0 or 1)**, where 1 means the patient has diabetes and 0 means they don't.\n"
      ],
      "metadata": {
        "id": "Ans1G1dqxc7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Predict Diabetes using Naive Bayes Classification"
      ],
      "metadata": {
        "id": "Vvpzocz1x9Hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtN4gU6ovaGi",
        "outputId": "39368b8c-cfa9-4c00-b2f3-335b523c2bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 1.00\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Pregnancies': [6, 1, 8, 1, 0, 5, 3, 10, 2, 8],\n",
        "    'Glucose': [148, 85, 183, 89, 137, 116, 78, 115, 197, 125],\n",
        "    'BloodPressure': [72, 66, 64, 66, 40, 74, 50, 0, 70, 96],\n",
        "    'SkinThickness': [35, 29, 0, 23, 35, 0, 32, 0, 45, 0],\n",
        "    'Insulin': [0, 0, 0, 94, 168, 0, 88, 0, 543, 0],\n",
        "    'BMI': [33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 30.0],\n",
        "    'DiabetesPedigreeFunction': [0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158, 0.232],\n",
        "    'Age': [50, 31, 32, 21, 33, 30, 26, 29, 53, 54],\n",
        "    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
        "}\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns='Outcome')\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_nb = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Predict Diabetes using ID3 Decision Tree Classifier"
      ],
      "metadata": {
        "id": "azFtb2EKyF46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset (same as above)\n",
        "data = {\n",
        "    'Pregnancies': [6, 1, 8, 1, 0, 5, 3, 10, 2, 8],\n",
        "    'Glucose': [148, 85, 183, 89, 137, 116, 78, 115, 197, 125],\n",
        "    'BloodPressure': [72, 66, 64, 66, 40, 74, 50, 0, 70, 96],\n",
        "    'SkinThickness': [35, 29, 0, 23, 35, 0, 32, 0, 45, 0],\n",
        "    'Insulin': [0, 0, 0, 94, 168, 0, 88, 0, 543, 0],\n",
        "    'BMI': [33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 30.0],\n",
        "    'DiabetesPedigreeFunction': [0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158, 0.232],\n",
        "    'Age': [50, 31, 32, 21, 33, 30, 26, 29, 53, 54],\n",
        "    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
        "}\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns='Outcome')\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjD7wC6gyKmE",
        "outputId": "8fe215ab-6eeb-4cc7-dcfe-52429dc4668f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.67\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Compare Performance of Both Classifiers"
      ],
      "metadata": {
        "id": "TcZNzTH2yOH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Calculate confusion matrices\n",
        "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "# Calculate ROC AUC scores\n",
        "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
        "roc_auc_dt = roc_auc_score(y_test, y_pred_dt)\n",
        "\n",
        "# Print comparison resultsprint(\"\\nNaive Bayes vs Decision Tree Classifier Performance:\\n\")\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
        "print(f\"Naive Bayes ROC AUC: {roc_auc_nb:.2f}\")\n",
        "print(f\"Decision Tree ROC AUC: {roc_auc_dt:.2f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix - Naive Bayes:\\n\", conf_matrix_nb)\n",
        "print(\"\\nConfusion Matrix - Decision Tree:\\n\", conf_matrix_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "P4kyE6vpyTYr",
        "outputId": "b88462fd-2afd-4273-81f3-0928352a698b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred_dt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3961249621.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate confusion matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconf_matrix_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconf_matrix_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate ROC AUC scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_dt' is not defined"
          ]
        }
      ]
    }
  ]
}